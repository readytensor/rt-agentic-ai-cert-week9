import pytest
from code.nodes.tag_generation_nodes import make_llm_tag_generator_node, make_tag_type_assigner_node
from code.consts import LLM_TAGS, SPACY_TAGS
from tests.integration_tests.utils.similarity import embed_and_score_similarity
from code.states.a3_state import initialize_a3_state


@pytest.mark.integration
def test_llm_tag_generator_node_integration(example1_data, a3_config, hf_embedder):
    """
    Integration test: checks whether LLM-generated tags are semantically relevant
    and overlap at least 50% with expected tags from the example file.
    """
    input_text, expected = example1_data
    expected_tags = expected.get("selected_tags", [])
    expected_tag_names = {tag["name"].lower() for tag in expected_tags}
    assert expected_tag_names, "Expected tags not found in example JSON"

    state = initialize_a3_state(config=a3_config, input_text=input_text)

    node = make_llm_tag_generator_node(
        llm_model=a3_config["agents"]["llm_tags_generator"]["llm"]
    )
    result = node(state)

    generated_tags = result.get(LLM_TAGS, [])
    assert generated_tags, "No tags generated by LLM"

    matched_count = 0
    for tag in generated_tags:
        name = tag["name"]
        if name in expected_tag_names:
            matched_count += 1
        else:
            # fallback: semantic similarity with any expected tag
            similarities = [
                embed_and_score_similarity(name, expected_name, hf_embedder)
                for expected_name in expected_tag_names
            ]
            if max(similarities, default=0.0) > 0.5:
                matched_count += 1

    match_rate = matched_count / len(expected_tag_names)
    assert match_rate >= 0.5, f"Match rate too low: {match_rate:.2f}"



@pytest.mark.integration
def test_tag_type_assigner_node_correctly_assigns_types(example1_data, a3_config, hf_embedder):
    """
    Integration test: verifies tag type assigner correctly labels expected tags
    and assigns 'other' to unknown/dummy tags like 'banana'.
    """
    input_text, expected = example1_data
    selected_tags  = expected.get("selected_tags", [])
    assert selected_tags , "No selected_tags found in example data."

    # Replace type with empty string
    incomplete_tags = [{"name": tag["name"], "type": ""} for tag in selected_tags]

    # Add a dummy tag with empty type
    incomplete_tags.append({"name": "banana", "type": ""})

    state = initialize_a3_state(config=a3_config, input_text=input_text)
    state[SPACY_TAGS] = incomplete_tags

    node = make_tag_type_assigner_node(
        llm_model=a3_config["agents"]["tag_type_assigner"]["llm"]
    )
    result = node(state)
    updated_tags = result[SPACY_TAGS]

    # Build expected type map
    expected_type_map = {tag["name"]: tag["type"] for tag in selected_tags}
    expected_type_map["banana"] = "other"

    # Count how many assigned types match expected ones
    matched = 0
    total = len(updated_tags)
    for tag in updated_tags:
        name = tag["name"]
        assigned_type = tag["type"]
        expected_type = expected_type_map.get(name)
        if expected_type is not None and assigned_type == expected_type:
            matched += 1

    match_ratio = matched / total
    assert match_ratio >= 0.5, (
        f"Only {matched}/{total} tags matched expected types "
        f"({match_ratio:.2%} match rate, expected â‰¥ 50%)"
    )


import pytest
from code.consts import (
    INPUT_TEXT,
    MANAGER_BRIEF,
    CANDIDATE_TAGS,
    TAGS_SELECTOR_MESSAGES,
    SELECTED_TAGS,
)
from code.nodes.tag_generation_nodes import make_tag_selector_node


@pytest.mark.integration
def test_tag_selector_node_returns_relevant_subset(example1_data, a3_config):
    """
    Integration test: tag selector node should return a filtered subset of candidate tags,
    containing no more than `max_tags`, with valid name/type fields.
    """
    input_text = example1_data[0]
    expected_tags = example1_data[1]["selected_tags"]
    expected_tag_names = {tag["name"] for tag in expected_tags}

    # Create candidate tags: expected + noise
    irrelevant_tags = [
        {"name": "banana", "type": "fruit"},
        {"name": "cat", "type": "animal"},
        {"name": "basketball", "type": "sport"},
    ]
    candidate_tags = expected_tags + irrelevant_tags
    irrelevant_tag_names = {t["name"] for t in irrelevant_tags}

    max_tags = 7
    state = initialize_a3_state(config=a3_config, input_text=input_text)
    state[CANDIDATE_TAGS] = candidate_tags

    node = make_tag_selector_node(llm_model=a3_config["agents"]["tags_selector"]["llm"], max_tags=max_tags)
    result = node(state)

    selected_tags = result.get(SELECTED_TAGS, [])

    assert selected_tags, "No tags returned from selector"
    # Ensure irrelevant tags are filtered
    selected_tag_names = {t["name"] for t in selected_tags}
    retained_irrelevant = irrelevant_tag_names & selected_tag_names

    assert not retained_irrelevant, f"Irrelevant tags were selected: {retained_irrelevant}"

    # Ensure most expected tags are retained
    retained_expected = expected_tag_names & selected_tag_names
    match_ratio = len(retained_expected) / len(expected_tag_names)

    assert match_ratio >= 0.7, (
        f"Only {len(retained_expected)}/{len(expected_tag_names)} expected tags retained "
        f"({match_ratio:.0%} match rate)"
    )